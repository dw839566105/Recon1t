{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin reading file\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_1.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_2.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_3.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_4.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_5.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_6.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_7.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_8.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_9.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_10.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_11.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_12.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_13.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_14.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_15.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_16.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_17.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_18.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_19.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_20.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_21.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_22.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_23.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_24.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_25.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_26.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_27.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_28.h5\n",
      "/mnt/stage/douwei/Simulation/1t_root/shell_200000/1t_+0.150_29.h5\n",
      "total event: 200000\n",
      "begin processing legendre coeff\n",
      "(28809802, 3) (28809802, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9a57cf6753f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0mPMT_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadPMT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m \u001b[0mmain_Calib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+0.150'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/mnt/stage/douwei/Simulation/1t_root/shell_200000/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mPMT_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-9a57cf6753f0>\u001b[0m in \u001b[0;36mmain_Calib\u001b[0;34m(radius, path, fout, cut_max, PMT_pos)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mvertex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPMT_pos_rep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mtmp_x_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLegendre_coeff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPMT_pos_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'use {time.time() - tmp} s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mLegendreCoeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_x_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9a57cf6753f0>\u001b[0m in \u001b[0;36mLegendre_coeff\u001b[0;34m(PMT_pos_rep, vertex, cut)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mcos_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;31m# legendre coeff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the heart of total PE calib\n",
    "The PE calib program use Poisson regression, which is equal to decomposition of log expect\n",
    "since the problem is spherical symmetric, we use Legendre polynomial\n",
    "\n",
    "    1. each PMT position 'x' and fixed vertex(or vertexes with the same radius r) 'v'\n",
    "    2. transform 'v' to (0,0,z) as an axis\n",
    "    3. do the same transform to x, we got the zenith angle 'theta' and azimuth angle 'phi', 'phi' can be ignored\n",
    "    4. calculate the different Legendre order of 'theta', as a big matrix 'X' (PMT No. * order)\n",
    "    5. expected 'y' by total pe, got GLM(generalize linear model) 'X beta = g(y)', 'beta' is a vector if coefficient, 'g' is link function, we use log\n",
    "    6. each r has a set of 'beta' for later analysis\n",
    "    \n",
    "The final optimize using scipy.optimize instead of sklear.**regression\n",
    "'''\n",
    "\n",
    "import numpy as np \n",
    "import scipy, h5py\n",
    "import tables\n",
    "import sys\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import rosen_der\n",
    "from numpy.polynomial import legendre as LG\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import norm\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "def LoadBase():\n",
    "    '''\n",
    "    # to vanish the PMT difference, just a easy script\n",
    "    # output: relative different bias\n",
    "    '''\n",
    "    path = './base.h5'\n",
    "    h1 = tables.open_file(path)\n",
    "    base = h1.root.correct[:]\n",
    "    h1.close()\n",
    "    return base\n",
    "# after using the same PMT this part can be omitted\n",
    "# base = np.log(LoadBase()) # dont forget log\n",
    "def ReadPMT():\n",
    "    '''\n",
    "    # Read PMT position\n",
    "    # output: 2d PMT position 30*3 (x, y, z)\n",
    "    '''\n",
    "    f = open(r\"./PMT_1t.txt\")\n",
    "    line = f.readline()\n",
    "    data_list = [] \n",
    "    while line:\n",
    "        num = list(map(float,line.split()))\n",
    "        data_list.append(num)\n",
    "        line = f.readline()\n",
    "    f.close()\n",
    "    PMT_pos = np.array(data_list)\n",
    "    return PMT_pos\n",
    "\n",
    "def Calib(theta, *args):\n",
    "    EventID, ChannelID, flight_time, PMT_pos, cut, LegendreCoeff, qt, ts = args\n",
    "    y = flight_time\n",
    "    T_i = np.dot(LegendreCoeff, theta)\n",
    "    # quantile regression\n",
    "    # quantile = 0.01\n",
    "    L0 = Likelihood_quantile(y, T_i, qt, ts, EventID)\n",
    "    L = L0 + np.sum(np.abs(theta))\n",
    "    return L0\n",
    "\n",
    "def Calib1(theta, *args):\n",
    "    t0, EventID, ChannelID, flight_time, PMT_pos, cut, LegendreCoeff = args\n",
    "    y = flight_time\n",
    "    T_i = np.dot(LegendreCoeff, np.hstack((theta[0],t0)))\n",
    "    # quantile regression\n",
    "    # quantile = 0.01\n",
    "    L0 = Likelihood_quantile(y, T_i, theta[1], 26, EventID)\n",
    "    L = L0 + np.sum(np.abs(theta))\n",
    "    print(theta, L0)\n",
    "    return L0\n",
    "\n",
    "def Likelihood_quantile(y, T_i, qt, ts, EventID):\n",
    "    #less = T_i[y<T_i] - y[y<T_i]\n",
    "    #more = y[y>=T_i] - T_i[y>=T_i]\n",
    "    #R = (1-tau)*np.sum(less) + tau*np.sum(more)\n",
    "    R = (1-qt)*(T_i-y)*(y<T_i) + (qt)*(y-T_i)*(y>=T_i)\n",
    "    H,edges =np.histogram(EventID, weights = R, bins = np.hstack((np.unique(EventID), np.max(EventID)+1)))\n",
    "    Q = np.bincount(EventID)\n",
    "    #L0 = 0\n",
    "    L = Q[1:]*np.log(qt*(1-qt)/ts) - H/ts\n",
    "    L0 = np.nansum(L)\n",
    "    return - L0\n",
    "\n",
    "def Legendre_coeff(PMT_pos_rep, vertex, cut):\n",
    "    '''\n",
    "    # calulate the Legendre value of transformed X\n",
    "    # input: PMT_pos: PMT No * 3\n",
    "          vertex: 'v' \n",
    "          cut: cut off of Legendre polynomial\n",
    "    # output: x: as 'X' at the beginnig    \n",
    "    \n",
    "    '''\n",
    "    size = np.size(PMT_pos_rep[:,0])\n",
    "    # oh, it will use norm in future version\n",
    "    \n",
    "    if(np.sum(vertex**2) > 1e-6):\n",
    "        cos_theta = np.sum(vertex*PMT_pos_rep,axis=1)\\\n",
    "            /np.sqrt(np.sum(vertex**2, axis=1)*np.sum(PMT_pos_rep**2,axis=1))\n",
    "    else:\n",
    "        # make r=0 as a boundry, it should be improved\n",
    "        cos_theta = np.ones(size)\n",
    "\n",
    "    x = np.zeros((size, cut))\n",
    "    # legendre coeff\n",
    "    for i in np.arange(0,cut):\n",
    "        c = np.zeros(cut)\n",
    "        c[i] = 1\n",
    "        x[:,i] = LG.legval(cos_theta,c)\n",
    "\n",
    "    print(PMT_pos_rep.shape, x.shape, cos_theta.shape)\n",
    "    return x, cos_theta\n",
    "\n",
    "def fun_der(x, *args):\n",
    "    total_pe, PMT_pos, cut, LegendreCoeff = args\n",
    "    #return rosen_der(Calib(x, *(total_pe, PMT_pos, cut, LegendreCoeff)))\n",
    "    #return Jacobian(Calib(x, *(total_pe, PMT_pos, cut, LegendreCoeff)))(x).ravel()\n",
    "    return Jacobian(Calib(x, *(total_pe, PMT_pos, cut, LegendreCoeff)))\n",
    "\n",
    "def fun_hess(x, *args):\n",
    "    total_pe, PMT_pos, cut, LegendreCoeff = args\n",
    "    return Hessian(Calib(x, *(total_pe, PMT_pos, cut, LegendreCoeff)))\n",
    "\n",
    "def MyHessian(x, *args):\n",
    "    # hession matrix calulation written by dw, for later uncertainty analysis\n",
    "    # it not be examed\n",
    "    # what if it is useful one day\n",
    "    total_pe, PMT_pos, cut, LegendreCoeff= args\n",
    "    H = np.zeros((len(x),len(x)))\n",
    "    h = 1e-6\n",
    "    k = 1e-6\n",
    "    for i in np.arange(len(x)):\n",
    "        for j in np.arange(len(x)):\n",
    "            if (i != j):\n",
    "                delta1 = np.zeros(len(x))\n",
    "                delta1[i] = h\n",
    "                delta1[j] = k\n",
    "                delta2 = np.zeros(len(x))\n",
    "                delta2[i] = -h\n",
    "                delta2[j] = k\n",
    "\n",
    "                L1 = - Calib(x + delta1, *(total_pe, PMT_pos, cut, LegendreCoeff))\n",
    "                L2 = - Calib(x - delta1, *(total_pe, PMT_pos, cut, LegendreCoeff))\n",
    "                L3 = - Calib(x + delta2, *(total_pe, PMT_pos, cut, LegendreCoeff))\n",
    "                L4 = - Calib(x - delta2, *(total_pe, PMT_pos, cut, LegendreCoeff))\n",
    "                H[i,j] = (L1+L2-L3-L4)/(4*h*k)\n",
    "            else:\n",
    "                delta = np.zeros(len(x))\n",
    "                delta[i] = h\n",
    "                L1 = - Calib(x + delta, *(total_pe, PMT_pos, cut, LegendreCoeff))\n",
    "                L2 = - Calib(x - delta, *(total_pe, PMT_pos, cut, LegendreCoeff))\n",
    "                L3 = - Calib(x, *(total_pe, PMT_pos, cut, LegendreCoeff))\n",
    "                H[i,j] = (L1+L2-2*L3)/h**2                \n",
    "    return H\n",
    "\n",
    "def readfile(filename):\n",
    "    '''\n",
    "    # Read single file\n",
    "    # input: filename [.h5]\n",
    "    # output: EventID, ChannelID, x, y, z\n",
    "    '''\n",
    "    h1 = tables.open_file(filename,'r')\n",
    "    print(filename, flush=True)\n",
    "    truthtable = h1.root.GroundTruth\n",
    "    EventID = truthtable[:]['EventID']\n",
    "    ChannelID = truthtable[:]['ChannelID']\n",
    "    PETime = truthtable[:]['PETime']\n",
    "    photonTime = truthtable[:]['photonTime']\n",
    "    PulseTime = truthtable[:]['PulseTime']\n",
    "    dETime = truthtable[:]['dETime']\n",
    "    \n",
    "    x = h1.root.TruthData[:]['x']\n",
    "    y = h1.root.TruthData[:]['y']\n",
    "    z = h1.root.TruthData[:]['z']\n",
    "    h1.close()\n",
    "    \n",
    "    # The following part is to avoid trigger by dn(dark noise) since threshold is 1\n",
    "    # These thiggers will be recorded as (0,0,0) by uproot\n",
    "    # but in root, the truth and the trigger is not one to one\n",
    "    # If the simulation vertex is (0,0,0), it is ambiguous, so we need cut off (0,0,0) or use data without dn\n",
    "    # If the simulation set -dn 0, whether the program will get into the following part is not tested\n",
    "    \n",
    "    dn = np.where((x==0) & (y==0) & (z==0))\n",
    "    dn_index = (x==0) & (y==0) & (z==0)\n",
    "    pin = dn[0] + np.min(EventID)\n",
    "    if(np.sum(x**2+y**2+z**2>0.1)>0):\n",
    "        cnt = 0        \n",
    "        for ID in np.arange(np.min(EventID), np.max(EventID)+1):\n",
    "            if ID in pin:\n",
    "                cnt = cnt+1\n",
    "                #print('Trigger No:', EventID[EventID==ID])\n",
    "                #print('Fired PMT', ChannelID[EventID==ID])\n",
    "                \n",
    "                ChannelID = ChannelID[~(EventID == ID)]\n",
    "                EventID = EventID[~(EventID == ID)]              \n",
    "                ChannelID = ChannelID[~(EventID == ID)]\n",
    "                PETime = PETime[~(EventID == ID)]\n",
    "                photonTime = photonTime[~(EventID == ID)]\n",
    "                PulseTime = PulseTime[~(EventID == ID)]\n",
    "                dETime = dETime[~(EventID == ID)]\n",
    "        x = x[~dn_index]\n",
    "        y = y[~dn_index]\n",
    "        z = z[~dn_index]\n",
    "    return (EventID, ChannelID, PETime, photonTime, PulseTime, dETime, x, y, z)\n",
    "    \n",
    "def readchain(radius, path, axis):\n",
    "    '''\n",
    "    # This program is to read series files\n",
    "    # Since root file will recorded as 'filename.root', if too large, it will use '_n' as suffix\n",
    "    # input: radius: %+.3f, 'str'\n",
    "    #        path: file storage path, 'str'\n",
    "    #        axis: 'x' or 'y' or 'z', 'str'\n",
    "    # output: the gathered result EventID, ChannelID, x, y, z\n",
    "    '''\n",
    "    for i in np.arange(0, 50):\n",
    "        if(i == 0):\n",
    "            # filename = path + '1t_' + radius + '.h5'\n",
    "            # eg: /mnt/stage/douwei/Simulation/1t_root/2.0MeV_xyz/1t_+0.030.h5\n",
    "            filename = '%s1t_%s.h5' % (path, radius)\n",
    "            EventID, ChannelID, PETime, photonTime, PulseTime, dETime, x, y, z = readfile(filename)\n",
    "        else:\n",
    "            try:\n",
    "                # filename = path + '1t_' + radius + '_n.h5'\n",
    "                # eg: /mnt/stage/douwei/Simulation/1t_root/2.0MeV_xyz/1t_+0.030_1.h5\n",
    "                filename = '%s1t_%s_%d.h5' % (path, radius, i)\n",
    "                EventID1, ChannelID1, PETime1, photonTime1, PulseTime1, dETime1, x1, y1, z1 = readfile(filename)\n",
    "                EventID = np.hstack((EventID, EventID1))\n",
    "                ChannelID = np.hstack((ChannelID, ChannelID1))\n",
    "                PETime = np.hstack((PETime,PETime1))\n",
    "                photonTime = np.hstack((photonTime, photonTime1))\n",
    "                PulseTime = np.hstack((PulseTime, PulseTime1))\n",
    "                dETime = np.hstack((dETime, dETime1))\n",
    "\n",
    "                x = np.hstack((x, x1))\n",
    "                y = np.hstack((y, y1))\n",
    "                z = np.hstack((z, z1))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return EventID, ChannelID, PETime, photonTime, PulseTime, dETime, x, y, z\n",
    "    \n",
    "def main_Calib(radius, path, fout, cut_max, PMT_pos):\n",
    "    '''\n",
    "    # main program\n",
    "    # input: radius: %+.3f, 'str' (in makefile, str is default)\n",
    "    #        path: file storage path, 'str'\n",
    "    #        fout: file output name as .h5, 'str' (.h5 not included')\n",
    "    #        cut_max: cut off of Legendre\n",
    "    # output: the gathered result EventID, ChannelID, x, y, z\n",
    "    '''\n",
    "    print('begin reading file', flush=True)\n",
    "    #filename = '/mnt/stage/douwei/Simulation/1t_root/1.5MeV_015/1t_' + radius + '.h5'\n",
    "    with h5py.File(fout,'w') as out:\n",
    "        EventID, ChannelID, PETime, photonTime, PulseTime, dETime, xx, yx, zx = readchain(radius, path,'+')\n",
    "        x1 = np.vstack((xx, yx, zx)).T\n",
    "        size = np.size(np.unique(EventID))\n",
    "        total_pe = np.zeros(np.size(PMT_pos[:,0])*size)\n",
    "        print('total event: %d' % np.size(np.unique(EventID)), flush=True)\n",
    "        \n",
    "        input_time = PETime\n",
    "        # input_time = PulseTime - photonTime\n",
    "        \n",
    "        print('begin processing legendre coeff', flush=True)\n",
    "        # this part for the same vertex\n",
    "        tmp = time.time()\n",
    "        EventNo = np.size(np.unique(EventID))\n",
    "        PMTNo = np.size(PMT_pos[:,0])\n",
    "        counts = np.bincount(EventID)\n",
    "        counts = counts[counts!=0]\n",
    "        PMT_pos_rep = PMT_pos[ChannelID]\n",
    "        vertex = np.repeat(x1, counts, axis=0)\n",
    "        print(PMT_pos_rep.shape, vertex.shape)\n",
    "        tmp_x_p, cos_theta = Legendre_coeff(PMT_pos_rep, vertex, cut_max)\n",
    "        print(f'use {time.time() - tmp} s')\n",
    "        LegendreCoeff = tmp_x_p\n",
    "\n",
    "PMT_pos = ReadPMT()\n",
    "main_Calib('+0.150','/mnt/stage/douwei/Simulation/1t_root/shell_200000/','test.h5',0.5 , PMT_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
